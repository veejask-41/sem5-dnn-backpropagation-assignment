{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data point, weights, and biases from CSV files\n",
    "data_point = np.array([-1, 1, 1, 1, -1, -1, 1, -1, 1, 1, -1, -1, 1, 1])\n",
    "target_label = np.array([3])\n",
    "\n",
    "\n",
    "w0_input_hidden1 = pd.read_csv(\n",
    "    r'Task_1\\a\\w.csv', index_col=0, nrows=14, header=None).values\n",
    "w0_hidden1_hidden2 = pd.read_csv(r'Task_1\\a\\w.csv', index_col=0, skiprows=range(14), nrows=100, usecols=range(41), header=None).values\n",
    "w0_hidden2_output = pd.read_csv(r'Task_1\\a\\w.csv', index_col=0, skiprows=range(114), nrows=40, usecols=range(5), header=None).values\n",
    "\n",
    "b0_hidden1 = pd.read_csv(\n",
    "    r'Task_1\\a\\b.csv', index_col=0, nrows=1, header=None).values\n",
    "b0_hidden2 = pd.read_csv(r'Task_1\\a\\b.csv', index_col=0, skiprows=range(1), nrows=1, usecols=range(41), header=None).values\n",
    "b0_output = pd.read_csv(r'Task_1\\a\\b.csv', index_col=0, skiprows=range(2), nrows=1, usecols=range(5), header=None).values\n",
    "\n",
    "w1_input_hidden1 = pd.read_csv(\n",
    "    r'Task_1\\b\\w-100-40-4.csv', index_col=0, nrows=14, header=None).values\n",
    "w1_hidden1_hidden2 = pd.read_csv(r'Task_1\\b\\w-100-40-4.csv', index_col=0, skiprows=range(14), nrows=100, usecols=range(41), header=None).values\n",
    "w1_hidden2_output = pd.read_csv(r'Task_1\\b\\w-100-40-4.csv', index_col=0, skiprows=range(114), nrows=40, usecols=range(5), header=None).values\n",
    "\n",
    "b1_hidden1 = pd.read_csv(\n",
    "    r'Task_1\\b\\b-100-40-4.csv', index_col=0, nrows=1, header=None).values\n",
    "b1_hidden2 = pd.read_csv(r'Task_1\\b\\b-100-40-4.csv', index_col=0, skiprows=range(1), nrows=1, usecols=range(41), header=None).values\n",
    "b1_output = pd.read_csv(r'Task_1\\b\\b-100-40-4.csv', index_col=0, skiprows=range(2), nrows=1, usecols=range(5), header=None).values\n",
    "\n",
    "correct_grad_w0_input_hidden1 = pd.read_csv(\n",
    "    r'Task_1\\a\\true-dw.csv', nrows=14, header=None).values\n",
    "correct_grad_w0_hidden1_hidden2 = pd.read_csv(r'Task_1\\a\\true-dw.csv', skiprows=range(14), nrows=100, usecols=range(40), header=None).values\n",
    "correct_grad_w0_hidden2_output = pd.read_csv(r'Task_1\\a\\true-dw.csv', skiprows=range(114), nrows=40, usecols=range(4), header=None).values\n",
    "\n",
    "correct_grad_b0_hidden1 = pd.read_csv(\n",
    "    r'Task_1\\a\\true-db.csv', nrows=1, header=None).values\n",
    "correct_grad_b0_hidden2 = pd.read_csv(r'Task_1\\a\\true-db.csv', skiprows=range(1), nrows=1, usecols=range(40), header=None).values\n",
    "correct_grad_b0_output = pd.read_csv(r'Task_1\\a\\true-db.csv', skiprows=range(2), nrows=1, usecols=range(4), header=None).values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define ReLU activation function and its derivative\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def relu_derivative(x):\n",
    "    return np.where(x > 0, 1, 0)\n",
    "\n",
    "# Define Softmax function\n",
    "def softmax(z):\n",
    "    exp_z = np.exp(z - np.max(z, axis=1, keepdims=True))  # Numerical stability\n",
    "    return exp_z / np.sum(exp_z, axis=1, keepdims=True)\n",
    "\n",
    "# Cross-entropy loss function\n",
    "def cross_entropy_loss(y_true, new_y_pred):\n",
    "    m = y_true.shape[0]\n",
    "    return -np.sum(y_true * np.log(new_y_pred + 1e-8)) / m\n",
    "\n",
    "# One-hot encoding for labels\n",
    "def one_hot_encode(y, num_classes):\n",
    "    one_hot = np.zeros((y.size, num_classes))\n",
    "    one_hot[np.arange(y.size), y] = 1\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_encode(target_label,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relu(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.81297987e-158, 5.20887762e-137, 1.00000000e+000,\n",
       "        2.00080740e-085]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_z1 = np.dot(data_point, w0_input_hidden1) + b0_hidden1\n",
    "new_a1 = relu(new_z1)\n",
    "\n",
    "new_z2 = np.dot(new_a1, w0_hidden1_hidden2) + b0_hidden2\n",
    "a2 = relu(new_z2)\n",
    "\n",
    "new_z3 = np.dot(a2, w0_hidden2_output) + b0_output\n",
    "new_a3 = softmax(new_z3)\n",
    "\n",
    "new_a3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.420680743952367"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_y_pred = new_a3\n",
    "y_true = one_hot_encode(target_label,4)\n",
    "\n",
    "cel = cross_entropy_loss(y_true, new_y_pred)\n",
    "cel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dz3 = y_pred - y_true\n",
    "dw3 = np.dot(a2.T, dz3)\n",
    "db3 = np.sum(dz3, axis=0, keepdims=True)\n",
    "\n",
    "dz2 = np.dot(dz3, w0_hidden2_output.T) * relu_derivative(a2)\n",
    "dw2 = np.dot(a1.T, dz2)\n",
    "db2 = np.sum(dz2, axis=0, keepdims=True)\n",
    "\n",
    "dz1 = np.dot(dz2, w0_hidden1_hidden2.T) * relu_derivative(a1)\n",
    "dw1 = np.dot(data_point.reshape(-1,1), dz1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, False, False, False, False, False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(dw1, correct_grad_w0_input_hidden1, atol=1e-8), np.allclose(dw2, correct_grad_w0_hidden1_hidden2, atol=1e-8), np.allclose(dw3, correct_grad_w0_hidden2_output, atol=1e-8), np.allclose(db1, correct_grad_b0_hidden1, atol=1e-8), np.allclose(db2, correct_grad_b0_hidden2, atol=1e-8), np.allclose(db3, correct_grad_b0_output, atol=1e-8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "z1 = np.dot(data_point, w1_input_hidden1) + b1_hidden1\n",
    "a1 = relu(z1)\n",
    "\n",
    "z2 = np.dot(a1, w1_hidden1_hidden2) + b1_hidden2\n",
    "a2 = relu(z2)\n",
    "\n",
    "z3 = np.dot(a2, w1_hidden2_output) + b1_output\n",
    "a3 = softmax(z3)\n",
    "\n",
    "y_pred = a3\n",
    "y_true = one_hot_encode(target_label,4)\n",
    "\n",
    "dz3 = y_pred - y_true\n",
    "dw3 = np.dot(a2.T, dz3)\n",
    "db3 = np.sum(dz3, axis=0, keepdims=True)\n",
    "\n",
    "dz2 = np.dot(dz3, w0_hidden2_output.T) * relu_derivative(a2)\n",
    "dw2 = np.dot(a1.T, dz2)\n",
    "db2 = np.sum(dz2, axis=0, keepdims=True)\n",
    "\n",
    "dz1 = np.dot(dz2, w0_hidden1_hidden2.T) * relu_derivative(a1)\n",
    "dw1 = np.dot(data_point.reshape(-1,1), dz1)\n",
    "db1 = np.sum(dz1, axis=0, keepdims=True)\n",
    "\n",
    "# save the gradients of weights and biases to specific csv files\n",
    "dw = pd.DataFrame(dw1)\n",
    "dw.to_csv(r'submission2\\true-dw.csv', header=False, index=False)\n",
    "\n",
    "# save the gradients of weights and biases to specific csv files\n",
    "dw = pd.DataFrame(dw2)\n",
    "dw.to_csv(r'submission2\\true-dw.csv', header=False, index=False, mode='a')\n",
    "\n",
    "# save the gradients of weights and biases to specific csv files\n",
    "dw = pd.DataFrame(dw3)\n",
    "dw.to_csv(r'submission2\\true-dw.csv', header=False, index=False, mode='a')\n",
    "\n",
    "db = pd.DataFrame(db1)\n",
    "db.to_csv(r'submission2\\true-db.csv', header=False, index=False)\n",
    "\n",
    "db = pd.DataFrame(db2)\n",
    "db.to_csv(r'submission2\\true-db.csv', header=False, index=False, mode='a')\n",
    "\n",
    "db = pd.DataFrame(db3)\n",
    "db.to_csv(r'submission2\\true-db.csv', header=False, index=False, mode='a')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the gradients of weights and biases to specific csv files\n",
    "dw = pd.DataFrame(dw1)\n",
    "dw.to_csv(r'submission\\true-dw.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the gradients of weights and biases to specific csv files\n",
    "dw = pd.DataFrame(dw2)\n",
    "dw.to_csv(r'submission\\true-dw.csv', header=False, index=False, mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the gradients of weights and biases to specific csv files\n",
    "dw = pd.DataFrame(dw3)\n",
    "dw.to_csv(r'submission\\true-dw.csv', header=False, index=False, mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = pd.DataFrame(db1)\n",
    "db.to_csv(r'submission\\true-db.csv', header=False, index=False)\n",
    "\n",
    "db = pd.DataFrame(db2)\n",
    "db.to_csv(r'submission\\true-db.csv', header=False, index=False, mode='a')\n",
    "\n",
    "db = pd.DataFrame(db3)\n",
    "db.to_csv(r'submission\\true-db.csv', header=False, index=False, mode='a')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dnn-assignment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
